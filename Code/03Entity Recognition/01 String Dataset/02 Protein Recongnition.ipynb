{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "import time\n",
    "\n",
    "def done():\n",
    "    frequency = 1000  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    \n",
    "    \n",
    "    for i in range(5):\n",
    "        winsound.Beep(frequency, duration)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import scispacy\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "def word2vec(x):\n",
    "    return nlp(x).vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing Proteins and Common English Words</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if os.path.isfile('dataset.npy') and os.path.isfile('proteinVectors.npy') and os.path.isfile('commonVectors.npy'):\n",
    "    dataset = np.load('dataset.npy', allow_pickle=True)\n",
    "    proteinVectors = np.load('proteinVectors.npy', allow_pickle=True)\n",
    "    commonVectors = np.load('commonVectors.npy', allow_pickle=True)\n",
    "else:\n",
    "    with open (\"protein_list.txt\", \"r\", encoding=\"utf8\") as myfile:\n",
    "        lines=myfile.readlines()\n",
    "        myfile.close()\n",
    "\n",
    "    proteins = [l.rstrip() for l in lines]    \n",
    "    print(len(proteins),\"proteins imported\")\n",
    "    \n",
    "        \n",
    "    import nltk\n",
    "    nltk.download('words')\n",
    "    from nltk.corpus import words\n",
    "    word_list = words.words()\n",
    "    # prints 236736\n",
    "    \n",
    "    word_list = random.sample(word_list,len(proteins))   \n",
    "   \n",
    "    \n",
    "    words = [w for w in word_list]\n",
    "    print(len(words),\"words imported\")\n",
    "    \n",
    "    \n",
    "    for p in proteins:\n",
    "        if p in words:\n",
    "            words.remove(p)\n",
    "            \n",
    "    proteinVectors = [word2vec(p) for p in proteins]\n",
    "    \n",
    "    commonVectors = [word2vec(w) for w in words]\n",
    "\n",
    "    dataset = [(p,1) for p in proteinVectors]    \n",
    "    print(\"done with converting proteins to vectors\")\n",
    "    \n",
    "    dataset += [(w,0) for w in commonVectors]\n",
    "    print(\"done with converting words to vectors\")\n",
    "\n",
    "    np.save('dataset.npy', dataset)\n",
    "    np.save('proteinVectors.npy', proteinVectors)\n",
    "    np.save('commonVectors.npy', commonVectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192418\n",
      "192418\n",
      "38484\n",
      "(96,)\n",
      "0 1\n",
      "1 1\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 1\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 1\n",
      "11 0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#print(dataset[0])\n",
    "\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "#print(dataset[0])\n",
    "\n",
    "#dataset = random.sample(dataset,len(dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectors = [l[0] for l in dataset]\n",
    "labels = [l[1] for l in dataset]\n",
    "\n",
    "print(len(vectors))\n",
    "print(len(labels))\n",
    "print(round(len(labels)/5))\n",
    "ratio = round(len(labels)/5)\n",
    "\n",
    "print(vectors[0].shape)\n",
    "\n",
    "for i,k in enumerate(labels):\n",
    "    print(i,k)\n",
    "    if i>10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38484\n",
      "153934\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "testSet = np.array(vectors[:ratio])\n",
    "testLabel = labels[:ratio]\n",
    "\n",
    "trainSet = np.array(vectors[ratio:])\n",
    "trainLabel = labels[ratio:]\n",
    "\n",
    "print(len(testSet))\n",
    "print(len(trainSet))\n",
    "print(type(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "for t in trainSet:\n",
    "    print(t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "vectorSize = trainSet[0].shape[0]\n",
    "print(vectorSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "#from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Imports work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Entity Recognition Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dense1Results = []\n",
    "Dense2Results = []\n",
    "Dense3Results = []\n",
    "\n",
    "\n",
    "all_epochs_to_run  = 1\n",
    "opt = 'adam'\n",
    "learningRate = 0.1\n",
    "epochs_to_run = all_epochs_to_run\n",
    "\n",
    "lossType = 'binary_crossentropy'#\"sparse_categorical_crossentropy\" #\"categorical_crossentropy\" #'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_run = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               9700      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 14,801\n",
      "Trainable params: 14,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Frost\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Starting training...\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\frost\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1942 - accuracy: 0.9263\n",
      "Epoch 2/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1586 - accuracy: 0.9413\n",
      "Epoch 3/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1494 - accuracy: 0.9447\n",
      "Epoch 4/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1443 - accuracy: 0.9468\n",
      "Epoch 5/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1402 - accuracy: 0.9483\n",
      "Epoch 6/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1370 - accuracy: 0.9496\n",
      "Epoch 7/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1339 - accuracy: 0.9513\n",
      "Epoch 8/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1313 - accuracy: 0.9521\n",
      "Epoch 9/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1289 - accuracy: 0.9532\n",
      "Epoch 10/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1269 - accuracy: 0.9537\n",
      "Epoch 11/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1246 - accuracy: 0.9541\n",
      "Epoch 12/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1225 - accuracy: 0.9554\n",
      "Epoch 13/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1216 - accuracy: 0.9557\n",
      "Epoch 14/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1198 - accuracy: 0.9561\n",
      "Epoch 15/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1187 - accuracy: 0.9567\n",
      "Epoch 16/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1171 - accuracy: 0.9572\n",
      "Epoch 17/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1161 - accuracy: 0.9576\n",
      "Epoch 18/100\n",
      "153934/153934 [==============================] - 12s 75us/step - loss: 0.1144 - accuracy: 0.9582\n",
      "Epoch 19/100\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.1129 - accuracy: 0.9593\n",
      "Epoch 20/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1126 - accuracy: 0.9589\n",
      "Epoch 21/100\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.1108 - accuracy: 0.9595\n",
      "Epoch 22/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1099 - accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.1090 - accuracy: 0.9605\n",
      "Epoch 24/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1082 - accuracy: 0.9603\n",
      "Epoch 25/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1072 - accuracy: 0.9609\n",
      "Epoch 26/100\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.1064 - accuracy: 0.9611\n",
      "Epoch 27/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1053 - accuracy: 0.9618\n",
      "Epoch 28/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1045 - accuracy: 0.9622\n",
      "Epoch 29/100\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.1033 - accuracy: 0.9623\n",
      "Epoch 30/100\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.1021 - accuracy: 0.9631\n",
      "Epoch 31/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1021 - accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1011 - accuracy: 0.9633\n",
      "Epoch 33/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0997 - accuracy: 0.9639\n",
      "Epoch 34/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0997 - accuracy: 0.9638\n",
      "Epoch 35/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0982 - accuracy: 0.9647\n",
      "Epoch 36/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0976 - accuracy: 0.9648\n",
      "Epoch 37/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0968 - accuracy: 0.9650\n",
      "Epoch 38/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0964 - accuracy: 0.9652\n",
      "Epoch 39/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0958 - accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0948 - accuracy: 0.9658\n",
      "Epoch 41/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0943 - accuracy: 0.9662\n",
      "Epoch 42/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0932 - accuracy: 0.9663\n",
      "Epoch 43/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0929 - accuracy: 0.9666\n",
      "Epoch 44/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0917 - accuracy: 0.9667\n",
      "Epoch 45/100\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0919 - accuracy: 0.9666\n",
      "Epoch 46/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0909 - accuracy: 0.9672\n",
      "Epoch 47/100\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0900 - accuracy: 0.9676\n",
      "Epoch 48/100\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0895 - accuracy: 0.9677\n",
      "Epoch 49/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0890 - accuracy: 0.9680\n",
      "Epoch 50/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0885 - accuracy: 0.9680\n",
      "Epoch 51/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0875 - accuracy: 0.9687\n",
      "Epoch 52/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0871 - accuracy: 0.9688\n",
      "Epoch 53/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0866 - accuracy: 0.9688\n",
      "Epoch 54/100\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0857 - accuracy: 0.9692\n",
      "Epoch 55/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0850 - accuracy: 0.9698\n",
      "Epoch 56/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0848 - accuracy: 0.9694\n",
      "Epoch 57/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0840 - accuracy: 0.9699\n",
      "Epoch 58/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0838 - accuracy: 0.9699\n",
      "Epoch 59/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0826 - accuracy: 0.9705\n",
      "Epoch 60/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0824 - accuracy: 0.9704\n",
      "Epoch 61/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0816 - accuracy: 0.9707\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0815 - accuracy: 0.9706\n",
      "Epoch 63/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0809 - accuracy: 0.9708\n",
      "Epoch 64/100\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0813 - accuracy: 0.9712\n",
      "Epoch 65/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0795 - accuracy: 0.9713\n",
      "Epoch 66/100\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0795 - accuracy: 0.9717\n",
      "Epoch 67/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0791 - accuracy: 0.9718\n",
      "Epoch 68/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0789 - accuracy: 0.9716\n",
      "Epoch 69/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0782 - accuracy: 0.9721\n",
      "Epoch 70/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0772 - accuracy: 0.9725\n",
      "Epoch 71/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0772 - accuracy: 0.9724\n",
      "Epoch 72/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0762 - accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0761 - accuracy: 0.9727\n",
      "Epoch 74/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0753 - accuracy: 0.9730\n",
      "Epoch 75/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0754 - accuracy: 0.9730\n",
      "Epoch 76/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0752 - accuracy: 0.9730\n",
      "Epoch 77/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0745 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0740 - accuracy: 0.9738\n",
      "Epoch 79/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0736 - accuracy: 0.9738\n",
      "Epoch 80/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0731 - accuracy: 0.9740\n",
      "Epoch 81/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0728 - accuracy: 0.9740\n",
      "Epoch 82/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0725 - accuracy: 0.9744\n",
      "Epoch 83/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0715 - accuracy: 0.9743\n",
      "Epoch 84/100\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0712 - accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0711 - accuracy: 0.9748\n",
      "Epoch 86/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0704 - accuracy: 0.9751\n",
      "Epoch 87/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0704 - accuracy: 0.9749\n",
      "Epoch 88/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0695 - accuracy: 0.9753\n",
      "Epoch 89/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0692 - accuracy: 0.9755\n",
      "Epoch 90/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0687 - accuracy: 0.9757\n",
      "Epoch 91/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0693 - accuracy: 0.9751\n",
      "Epoch 92/100\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0680 - accuracy: 0.9759\n",
      "Epoch 93/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0682 - accuracy: 0.9757\n",
      "Epoch 94/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0676 - accuracy: 0.9759\n",
      "Epoch 95/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0669 - accuracy: 0.9764\n",
      "Epoch 96/100\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0668 - accuracy: 0.9762\n",
      "Epoch 97/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0664 - accuracy: 0.9764\n",
      "Epoch 98/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0658 - accuracy: 0.9763\n",
      "Epoch 99/100\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0655 - accuracy: 0.9767\n",
      "Epoch 100/100\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0649 - accuracy: 0.9766\n",
      "\n",
      "Training done in 17.784030783176423 minutes or 1067.0418469905853 seconds now evaluating...\n",
      "\n",
      "153934/153934 [==============================] - 4s 26us/step\n",
      "\n",
      "38484/38484 [==============================] - 1s 26us/step\n",
      "[[0.68586874]]\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(vectorSize,))\n",
    "\n",
    "#x = Dense(8000, activation='sigmoid')(input_layer)\n",
    "\n",
    "#x = Dense(4000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(2000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(1000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(500, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(100, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(50, activation='sigmoid')(x)\n",
    "\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mlp1 = keras.models.Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "mlp1.summary()\n",
    "\n",
    "\n",
    "#compile\n",
    "mlp1.compile(optimizer=opt, loss=lossType, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Starting training...\")\n",
    "print()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# fit the model\n",
    "mlp1.fit(trainSet, trainLabel, epochs=epochs_to_run, verbose=1)\n",
    "\n",
    "durationSecond = time.time()-start\n",
    "\n",
    "print()\n",
    "print(\"Training done in\",durationSecond/60,\"minutes or\",durationSecond,\"seconds now evaluating...\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "trainLoss, trainAccuracy = mlp1.evaluate(trainSet, trainLabel, verbose=1)\n",
    "#print('Training Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "testLoss, testAccuracy = mlp1.evaluate(testSet, testLabel, verbose=1)\n",
    "#print('Test Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "\n",
    "word = \"dystrophin\"\n",
    "\n",
    "prediction = mlp1.predict(np.array([word2vec(word)]))\n",
    "\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "Dense1Results += [trainAccuracy,testAccuracy]\n",
    "\n",
    "#del model\n",
    "\n",
    "#backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_run = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               9700      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 14,801\n",
      "Trainable params: 14,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1932 - accuracy: 0.9265\n",
      "Epoch 2/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1579 - accuracy: 0.9413\n",
      "Epoch 3/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1493 - accuracy: 0.9446\n",
      "Epoch 4/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1441 - accuracy: 0.9469\n",
      "Epoch 5/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1405 - accuracy: 0.9487\n",
      "Epoch 6/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1369 - accuracy: 0.9501\n",
      "Epoch 7/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1336 - accuracy: 0.9517\n",
      "Epoch 8/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1318 - accuracy: 0.9517\n",
      "Epoch 9/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1290 - accuracy: 0.9530\n",
      "Epoch 10/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1277 - accuracy: 0.9532\n",
      "Epoch 11/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1255 - accuracy: 0.9544\n",
      "Epoch 12/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1234 - accuracy: 0.9551\n",
      "Epoch 13/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1220 - accuracy: 0.9560\n",
      "Epoch 14/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1205 - accuracy: 0.9568\n",
      "Epoch 15/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1188 - accuracy: 0.9569\n",
      "Epoch 16/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1174 - accuracy: 0.9576\n",
      "Epoch 17/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1160 - accuracy: 0.9582\n",
      "Epoch 18/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1148 - accuracy: 0.9585\n",
      "Epoch 19/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1131 - accuracy: 0.9590\n",
      "Epoch 20/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1121 - accuracy: 0.9594\n",
      "Epoch 21/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1111 - accuracy: 0.9597\n",
      "Epoch 22/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1097 - accuracy: 0.9601\n",
      "Epoch 23/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1085 - accuracy: 0.9609\n",
      "Epoch 24/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1076 - accuracy: 0.9611\n",
      "Epoch 25/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.1060 - accuracy: 0.9614\n",
      "Epoch 26/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1059 - accuracy: 0.9617\n",
      "Epoch 27/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1050 - accuracy: 0.9618\n",
      "Epoch 28/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1036 - accuracy: 0.9623\n",
      "Epoch 29/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1027 - accuracy: 0.9629\n",
      "Epoch 30/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.1017 - accuracy: 0.9634\n",
      "Epoch 31/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.1003 - accuracy: 0.9635\n",
      "Epoch 32/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0997 - accuracy: 0.9636\n",
      "Epoch 33/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0989 - accuracy: 0.9645\n",
      "Epoch 34/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0979 - accuracy: 0.9649\n",
      "Epoch 35/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0974 - accuracy: 0.9647\n",
      "Epoch 36/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0965 - accuracy: 0.9650\n",
      "Epoch 37/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0958 - accuracy: 0.9657\n",
      "Epoch 38/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0952 - accuracy: 0.9655\n",
      "Epoch 39/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0944 - accuracy: 0.9658\n",
      "Epoch 40/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0933 - accuracy: 0.9664\n",
      "Epoch 41/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.0928 - accuracy: 0.9667\n",
      "Epoch 42/200\n",
      "153934/153934 [==============================] - 10s 65us/step - loss: 0.0923 - accuracy: 0.9668\n",
      "Epoch 43/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0914 - accuracy: 0.9674\n",
      "Epoch 44/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0901 - accuracy: 0.9676\n",
      "Epoch 45/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0900 - accuracy: 0.9674\n",
      "Epoch 46/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0892 - accuracy: 0.9678\n",
      "Epoch 47/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0885 - accuracy: 0.9682\n",
      "Epoch 48/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0880 - accuracy: 0.9685\n",
      "Epoch 49/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0873 - accuracy: 0.9685\n",
      "Epoch 50/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0866 - accuracy: 0.9691\n",
      "Epoch 51/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0862 - accuracy: 0.9694\n",
      "Epoch 52/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0853 - accuracy: 0.9692\n",
      "Epoch 53/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0849 - accuracy: 0.9695\n",
      "Epoch 54/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0848 - accuracy: 0.9694\n",
      "Epoch 55/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0834 - accuracy: 0.9699\n",
      "Epoch 56/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0832 - accuracy: 0.9700\n",
      "Epoch 57/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0830 - accuracy: 0.9702\n",
      "Epoch 58/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0823 - accuracy: 0.9702\n",
      "Epoch 59/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0810 - accuracy: 0.9708\n",
      "Epoch 60/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0807 - accuracy: 0.9710\n",
      "Epoch 61/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0799 - accuracy: 0.9713\n",
      "Epoch 62/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0802 - accuracy: 0.9712\n",
      "Epoch 63/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0788 - accuracy: 0.9717\n",
      "Epoch 64/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0791 - accuracy: 0.9714\n",
      "Epoch 65/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0778 - accuracy: 0.9722\n",
      "Epoch 66/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0773 - accuracy: 0.9724\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0771 - accuracy: 0.9720\n",
      "Epoch 68/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0767 - accuracy: 0.9722\n",
      "Epoch 69/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0762 - accuracy: 0.9726\n",
      "Epoch 70/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0752 - accuracy: 0.9732\n",
      "Epoch 71/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0749 - accuracy: 0.9732\n",
      "Epoch 72/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0744 - accuracy: 0.9732\n",
      "Epoch 73/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0743 - accuracy: 0.9733\n",
      "Epoch 74/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0733 - accuracy: 0.9738\n",
      "Epoch 75/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0736 - accuracy: 0.9737\n",
      "Epoch 76/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0728 - accuracy: 0.9741\n",
      "Epoch 77/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0727 - accuracy: 0.9739\n",
      "Epoch 78/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0718 - accuracy: 0.9740\n",
      "Epoch 79/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0709 - accuracy: 0.9745\n",
      "Epoch 80/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0709 - accuracy: 0.9745\n",
      "Epoch 81/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0710 - accuracy: 0.9746\n",
      "Epoch 82/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0700 - accuracy: 0.9749\n",
      "Epoch 83/200\n",
      "153934/153934 [==============================] - 12s 78us/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 84/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0689 - accuracy: 0.9749\n",
      "Epoch 85/200\n",
      "153934/153934 [==============================] - 11s 75us/step - loss: 0.0691 - accuracy: 0.9751\n",
      "Epoch 86/200\n",
      "153934/153934 [==============================] - 12s 81us/step - loss: 0.0681 - accuracy: 0.9755\n",
      "Epoch 87/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0683 - accuracy: 0.9754\n",
      "Epoch 88/200\n",
      "153934/153934 [==============================] - 12s 77us/step - loss: 0.0676 - accuracy: 0.9758\n",
      "Epoch 89/200\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0667 - accuracy: 0.9759\n",
      "Epoch 90/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0668 - accuracy: 0.9759\n",
      "Epoch 91/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0665 - accuracy: 0.9764\n",
      "Epoch 92/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0655 - accuracy: 0.9763\n",
      "Epoch 93/200\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0649 - accuracy: 0.9769\n",
      "Epoch 94/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0649 - accuracy: 0.9767\n",
      "Epoch 95/200\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0648 - accuracy: 0.9769\n",
      "Epoch 96/200\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0645 - accuracy: 0.9771\n",
      "Epoch 97/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0642 - accuracy: 0.9771\n",
      "Epoch 98/200\n",
      "153934/153934 [==============================] - 12s 76us/step - loss: 0.0632 - accuracy: 0.9776\n",
      "Epoch 99/200\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0633 - accuracy: 0.9775\n",
      "Epoch 100/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0632 - accuracy: 0.9774\n",
      "Epoch 101/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0618 - accuracy: 0.9779\n",
      "Epoch 102/200\n",
      "153934/153934 [==============================] - 11s 74us/step - loss: 0.0627 - accuracy: 0.9776\n",
      "Epoch 103/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0615 - accuracy: 0.9779\n",
      "Epoch 104/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0608 - accuracy: 0.9782\n",
      "Epoch 105/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0611 - accuracy: 0.9780\n",
      "Epoch 106/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0606 - accuracy: 0.9782\n",
      "Epoch 107/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0606 - accuracy: 0.9784\n",
      "Epoch 108/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0599 - accuracy: 0.9787\n",
      "Epoch 109/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0599 - accuracy: 0.9784\n",
      "Epoch 110/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0597 - accuracy: 0.9787\n",
      "Epoch 111/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0588 - accuracy: 0.9788\n",
      "Epoch 112/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0588 - accuracy: 0.9791\n",
      "Epoch 113/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0586 - accuracy: 0.9790\n",
      "Epoch 114/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0574 - accuracy: 0.9796\n",
      "Epoch 115/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0578 - accuracy: 0.9792\n",
      "Epoch 116/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0577 - accuracy: 0.9791\n",
      "Epoch 117/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0570 - accuracy: 0.9794\n",
      "Epoch 118/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0572 - accuracy: 0.9794\n",
      "Epoch 119/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0565 - accuracy: 0.9796\n",
      "Epoch 120/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0557 - accuracy: 0.9800\n",
      "Epoch 121/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0562 - accuracy: 0.9801\n",
      "Epoch 122/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0560 - accuracy: 0.9799\n",
      "Epoch 123/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0556 - accuracy: 0.9802\n",
      "Epoch 124/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0549 - accuracy: 0.9804\n",
      "Epoch 125/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0550 - accuracy: 0.9803\n",
      "Epoch 126/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0551 - accuracy: 0.9803\n",
      "Epoch 127/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0541 - accuracy: 0.9805\n",
      "Epoch 128/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0537 - accuracy: 0.9808\n",
      "Epoch 129/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0539 - accuracy: 0.9803\n",
      "Epoch 130/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0538 - accuracy: 0.9808\n",
      "Epoch 131/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0531 - accuracy: 0.9810\n",
      "Epoch 132/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0525 - accuracy: 0.9809\n",
      "Epoch 133/200\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0529 - accuracy: 0.9811\n",
      "Epoch 134/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0534 - accuracy: 0.9812\n",
      "Epoch 135/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0524 - accuracy: 0.9813\n",
      "Epoch 136/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0516 - accuracy: 0.9815\n",
      "Epoch 137/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0519 - accuracy: 0.9814\n",
      "Epoch 138/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0516 - accuracy: 0.9818\n",
      "Epoch 139/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0509 - accuracy: 0.9814\n",
      "Epoch 140/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0513 - accuracy: 0.9817\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0508 - accuracy: 0.9817\n",
      "Epoch 142/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0504 - accuracy: 0.9817\n",
      "Epoch 143/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0500 - accuracy: 0.9822\n",
      "Epoch 144/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0505 - accuracy: 0.9822\n",
      "Epoch 145/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0502 - accuracy: 0.9821\n",
      "Epoch 146/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0497 - accuracy: 0.9822\n",
      "Epoch 147/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0494 - accuracy: 0.9824\n",
      "Epoch 148/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0488 - accuracy: 0.9827\n",
      "Epoch 149/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0492 - accuracy: 0.9823\n",
      "Epoch 150/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0487 - accuracy: 0.9825\n",
      "Epoch 151/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0483 - accuracy: 0.9826\n",
      "Epoch 152/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0482 - accuracy: 0.9824\n",
      "Epoch 153/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0482 - accuracy: 0.9827\n",
      "Epoch 154/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0481 - accuracy: 0.9831\n",
      "Epoch 155/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0482 - accuracy: 0.9829\n",
      "Epoch 156/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0477 - accuracy: 0.9828\n",
      "Epoch 157/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0470 - accuracy: 0.9832\n",
      "Epoch 158/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0467 - accuracy: 0.9834\n",
      "Epoch 159/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0471 - accuracy: 0.9830\n",
      "Epoch 160/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0474 - accuracy: 0.9830\n",
      "Epoch 161/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0466 - accuracy: 0.9832\n",
      "Epoch 162/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0459 - accuracy: 0.9833\n",
      "Epoch 163/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0458 - accuracy: 0.9836\n",
      "Epoch 164/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0460 - accuracy: 0.9836\n",
      "Epoch 165/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0461 - accuracy: 0.9833\n",
      "Epoch 166/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0459 - accuracy: 0.9832\n",
      "Epoch 167/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0452 - accuracy: 0.9840\n",
      "Epoch 168/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0453 - accuracy: 0.9841\n",
      "Epoch 169/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0454 - accuracy: 0.9840\n",
      "Epoch 170/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0448 - accuracy: 0.9840\n",
      "Epoch 171/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0455 - accuracy: 0.9837\n",
      "Epoch 172/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0435 - accuracy: 0.9844\n",
      "Epoch 173/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0441 - accuracy: 0.9841\n",
      "Epoch 174/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0432 - accuracy: 0.9844\n",
      "Epoch 175/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0437 - accuracy: 0.9844\n",
      "Epoch 176/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0434 - accuracy: 0.9844\n",
      "Epoch 177/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0429 - accuracy: 0.9848\n",
      "Epoch 178/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0430 - accuracy: 0.9845\n",
      "Epoch 179/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0433 - accuracy: 0.9844\n",
      "Epoch 180/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0426 - accuracy: 0.9848\n",
      "Epoch 181/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0427 - accuracy: 0.9851\n",
      "Epoch 182/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0426 - accuracy: 0.9848\n",
      "Epoch 183/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0428 - accuracy: 0.9849\n",
      "Epoch 184/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0417 - accuracy: 0.9850\n",
      "Epoch 185/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0427 - accuracy: 0.9845\n",
      "Epoch 186/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0418 - accuracy: 0.9849\n",
      "Epoch 187/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0412 - accuracy: 0.9850\n",
      "Epoch 188/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0417 - accuracy: 0.9850\n",
      "Epoch 189/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0420 - accuracy: 0.9851\n",
      "Epoch 190/200\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0412 - accuracy: 0.9850\n",
      "Epoch 191/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0406 - accuracy: 0.9853\n",
      "Epoch 192/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0412 - accuracy: 0.9849\n",
      "Epoch 193/200\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0416 - accuracy: 0.9850\n",
      "Epoch 194/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0411 - accuracy: 0.9851\n",
      "Epoch 195/200\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0405 - accuracy: 0.9855\n",
      "Epoch 196/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0403 - accuracy: 0.9857\n",
      "Epoch 197/200\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0399 - accuracy: 0.9856\n",
      "Epoch 198/200\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0408 - accuracy: 0.9851\n",
      "Epoch 199/200\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0404 - accuracy: 0.9855\n",
      "Epoch 200/200\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0394 - accuracy: 0.9856\n",
      "\n",
      "Training done in 35.042882951100665 minutes or 2102.57297706604 seconds now evaluating...\n",
      "\n",
      "153934/153934 [==============================] - 4s 27us/step\n",
      "\n",
      "38484/38484 [==============================] - 1s 28us/step\n",
      "[[0.3250093]]\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(vectorSize,))\n",
    "\n",
    "#x = Dense(8000, activation='sigmoid')(input_layer)\n",
    "\n",
    "#x = Dense(4000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(2000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(1000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(500, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(100, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(50, activation='sigmoid')(x)\n",
    "\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mlp2 = keras.models.Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "mlp2.summary()\n",
    "\n",
    "\n",
    "#compile\n",
    "mlp2.compile(optimizer=opt, loss=lossType, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Starting training...\")\n",
    "print()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# fit the model\n",
    "mlp2.fit(trainSet, trainLabel, epochs=epochs_to_run, verbose=1)\n",
    "\n",
    "durationSecond = time.time()-start\n",
    "\n",
    "print()\n",
    "print(\"Training done in\",durationSecond/60,\"minutes or\",durationSecond,\"seconds now evaluating...\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "trainLoss, trainAccuracy = mlp2.evaluate(trainSet, trainLabel, verbose=1)\n",
    "#print('Training Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "testLoss, testAccuracy = mlp2.evaluate(testSet, testLabel, verbose=1)\n",
    "#print('Test Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "\n",
    "word = \"dystrophin\"\n",
    "\n",
    "prediction = mlp2.predict(np.array([word2vec(word)]))\n",
    "\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "Dense2Results += [trainAccuracy,testAccuracy]\n",
    "\n",
    "#del model\n",
    "\n",
    "#backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_run = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               9700      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 14,801\n",
      "Trainable params: 14,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1931 - accuracy: 0.9268\n",
      "Epoch 2/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1576 - accuracy: 0.9414\n",
      "Epoch 3/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1488 - accuracy: 0.9454\n",
      "Epoch 4/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1433 - accuracy: 0.9476\n",
      "Epoch 5/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1387 - accuracy: 0.9492\n",
      "Epoch 6/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1359 - accuracy: 0.9503\n",
      "Epoch 7/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1324 - accuracy: 0.9515\n",
      "Epoch 8/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1308 - accuracy: 0.9525\n",
      "Epoch 9/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1287 - accuracy: 0.9535\n",
      "Epoch 10/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1261 - accuracy: 0.9541\n",
      "Epoch 11/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1247 - accuracy: 0.9544\n",
      "Epoch 12/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1228 - accuracy: 0.9552\n",
      "Epoch 13/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1210 - accuracy: 0.9563\n",
      "Epoch 14/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1198 - accuracy: 0.9569\n",
      "Epoch 15/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1183 - accuracy: 0.9572\n",
      "Epoch 16/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1167 - accuracy: 0.9577\n",
      "Epoch 17/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1150 - accuracy: 0.9580\n",
      "Epoch 18/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1140 - accuracy: 0.9584\n",
      "Epoch 19/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1131 - accuracy: 0.9588\n",
      "Epoch 20/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1117 - accuracy: 0.9597\n",
      "Epoch 21/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1109 - accuracy: 0.9596\n",
      "Epoch 22/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1090 - accuracy: 0.9606\n",
      "Epoch 23/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1087 - accuracy: 0.9607\n",
      "Epoch 24/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.1073 - accuracy: 0.9614\n",
      "Epoch 25/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.1070 - accuracy: 0.9614\n",
      "Epoch 26/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1056 - accuracy: 0.9621\n",
      "Epoch 27/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1046 - accuracy: 0.9623\n",
      "Epoch 28/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1037 - accuracy: 0.9625\n",
      "Epoch 29/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.1026 - accuracy: 0.9633\n",
      "Epoch 30/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.1022 - accuracy: 0.9635\n",
      "Epoch 31/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.1009 - accuracy: 0.9634\n",
      "Epoch 32/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0999 - accuracy: 0.9640\n",
      "Epoch 33/300\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0988 - accuracy: 0.9645\n",
      "Epoch 34/300\n",
      "153934/153934 [==============================] - 12s 76us/step - loss: 0.0983 - accuracy: 0.9647\n",
      "Epoch 35/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0975 - accuracy: 0.9650\n",
      "Epoch 36/300\n",
      "153934/153934 [==============================] - 13s 81us/step - loss: 0.0970 - accuracy: 0.9652\n",
      "Epoch 37/300\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0959 - accuracy: 0.9657\n",
      "Epoch 38/300\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0949 - accuracy: 0.9661\n",
      "Epoch 39/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0949 - accuracy: 0.9660\n",
      "Epoch 40/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0940 - accuracy: 0.9664\n",
      "Epoch 41/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0930 - accuracy: 0.9664\n",
      "Epoch 42/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0926 - accuracy: 0.9667\n",
      "Epoch 43/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0917 - accuracy: 0.9675\n",
      "Epoch 44/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0909 - accuracy: 0.9676\n",
      "Epoch 45/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0902 - accuracy: 0.9677\n",
      "Epoch 46/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0893 - accuracy: 0.9684\n",
      "Epoch 47/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0888 - accuracy: 0.9683\n",
      "Epoch 48/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0882 - accuracy: 0.9687\n",
      "Epoch 49/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0878 - accuracy: 0.9688\n",
      "Epoch 50/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0871 - accuracy: 0.9692\n",
      "Epoch 51/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0865 - accuracy: 0.9696\n",
      "Epoch 52/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0857 - accuracy: 0.9698\n",
      "Epoch 53/300\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0851 - accuracy: 0.9698\n",
      "Epoch 54/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0845 - accuracy: 0.9700\n",
      "Epoch 55/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0842 - accuracy: 0.9704\n",
      "Epoch 56/300\n",
      "153934/153934 [==============================] - 11s 74us/step - loss: 0.0839 - accuracy: 0.9700\n",
      "Epoch 57/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0828 - accuracy: 0.9706\n",
      "Epoch 58/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0824 - accuracy: 0.9708\n",
      "Epoch 59/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0817 - accuracy: 0.9711\n",
      "Epoch 60/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0814 - accuracy: 0.9710\n",
      "Epoch 61/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0810 - accuracy: 0.9713\n",
      "Epoch 62/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0803 - accuracy: 0.9714\n",
      "Epoch 63/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0798 - accuracy: 0.9720\n",
      "Epoch 64/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0795 - accuracy: 0.9722\n",
      "Epoch 65/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0786 - accuracy: 0.9722\n",
      "Epoch 66/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0788 - accuracy: 0.9719\n",
      "Epoch 67/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 11s 74us/step - loss: 0.0773 - accuracy: 0.9728\n",
      "Epoch 68/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0776 - accuracy: 0.9727\n",
      "Epoch 69/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0772 - accuracy: 0.9729\n",
      "Epoch 70/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0766 - accuracy: 0.9730\n",
      "Epoch 71/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0758 - accuracy: 0.9732\n",
      "Epoch 72/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0753 - accuracy: 0.9733\n",
      "Epoch 73/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0751 - accuracy: 0.9737\n",
      "Epoch 74/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0744 - accuracy: 0.9740\n",
      "Epoch 75/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0737 - accuracy: 0.9742\n",
      "Epoch 76/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0738 - accuracy: 0.9742\n",
      "Epoch 77/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0733 - accuracy: 0.9742\n",
      "Epoch 78/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0731 - accuracy: 0.9742\n",
      "Epoch 79/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0721 - accuracy: 0.9748\n",
      "Epoch 80/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0719 - accuracy: 0.9747\n",
      "Epoch 81/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0716 - accuracy: 0.9750\n",
      "Epoch 82/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0706 - accuracy: 0.9750\n",
      "Epoch 83/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0705 - accuracy: 0.9751\n",
      "Epoch 84/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0706 - accuracy: 0.9752\n",
      "Epoch 85/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0699 - accuracy: 0.9758\n",
      "Epoch 86/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0687 - accuracy: 0.9762\n",
      "Epoch 87/300\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0696 - accuracy: 0.9753\n",
      "Epoch 88/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0689 - accuracy: 0.9758\n",
      "Epoch 89/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0686 - accuracy: 0.9762\n",
      "Epoch 90/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0678 - accuracy: 0.9764\n",
      "Epoch 91/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0677 - accuracy: 0.9764\n",
      "Epoch 92/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0675 - accuracy: 0.9765\n",
      "Epoch 93/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0666 - accuracy: 0.9770\n",
      "Epoch 94/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0667 - accuracy: 0.9770\n",
      "Epoch 95/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0659 - accuracy: 0.9773\n",
      "Epoch 96/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0656 - accuracy: 0.9775\n",
      "Epoch 97/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0653 - accuracy: 0.9776\n",
      "Epoch 98/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0650 - accuracy: 0.9773\n",
      "Epoch 99/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0651 - accuracy: 0.9772\n",
      "Epoch 100/300\n",
      "153934/153934 [==============================] - 11s 73us/step - loss: 0.0638 - accuracy: 0.9779\n",
      "Epoch 101/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0648 - accuracy: 0.9773\n",
      "Epoch 102/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0641 - accuracy: 0.9775\n",
      "Epoch 103/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0632 - accuracy: 0.9781\n",
      "Epoch 104/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0630 - accuracy: 0.9781\n",
      "Epoch 105/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0625 - accuracy: 0.9786\n",
      "Epoch 106/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0627 - accuracy: 0.9782\n",
      "Epoch 107/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0624 - accuracy: 0.9780\n",
      "Epoch 108/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0623 - accuracy: 0.9784\n",
      "Epoch 109/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0622 - accuracy: 0.9783\n",
      "Epoch 110/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0614 - accuracy: 0.9788\n",
      "Epoch 111/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0611 - accuracy: 0.9787\n",
      "Epoch 112/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0611 - accuracy: 0.9785\n",
      "Epoch 113/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0608 - accuracy: 0.9789\n",
      "Epoch 114/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0600 - accuracy: 0.9793\n",
      "Epoch 115/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0602 - accuracy: 0.9791\n",
      "Epoch 116/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0600 - accuracy: 0.9791\n",
      "Epoch 117/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0590 - accuracy: 0.9794\n",
      "Epoch 118/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0595 - accuracy: 0.9795\n",
      "Epoch 119/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0588 - accuracy: 0.9797\n",
      "Epoch 120/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0580 - accuracy: 0.9800\n",
      "Epoch 121/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0582 - accuracy: 0.9800\n",
      "Epoch 122/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 123/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0582 - accuracy: 0.9797\n",
      "Epoch 124/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 125/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0572 - accuracy: 0.9799\n",
      "Epoch 126/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0564 - accuracy: 0.9804\n",
      "Epoch 127/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0565 - accuracy: 0.9804\n",
      "Epoch 128/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0560 - accuracy: 0.9806\n",
      "Epoch 129/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0567 - accuracy: 0.9803\n",
      "Epoch 130/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0558 - accuracy: 0.9806\n",
      "Epoch 131/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0555 - accuracy: 0.9808\n",
      "Epoch 132/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0557 - accuracy: 0.9807\n",
      "Epoch 133/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0555 - accuracy: 0.9806\n",
      "Epoch 134/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0550 - accuracy: 0.9810\n",
      "Epoch 135/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0548 - accuracy: 0.9811\n",
      "Epoch 136/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0545 - accuracy: 0.9813\n",
      "Epoch 137/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0543 - accuracy: 0.9811\n",
      "Epoch 138/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0538 - accuracy: 0.9815\n",
      "Epoch 139/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0538 - accuracy: 0.9812\n",
      "Epoch 140/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0532 - accuracy: 0.9816\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0540 - accuracy: 0.9814\n",
      "Epoch 142/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0530 - accuracy: 0.9816\n",
      "Epoch 143/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0527 - accuracy: 0.9818\n",
      "Epoch 144/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0523 - accuracy: 0.9823\n",
      "Epoch 145/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0529 - accuracy: 0.9813\n",
      "Epoch 146/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0521 - accuracy: 0.9818\n",
      "Epoch 147/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0521 - accuracy: 0.9820\n",
      "Epoch 148/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0523 - accuracy: 0.9821\n",
      "Epoch 149/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0516 - accuracy: 0.9822\n",
      "Epoch 150/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0515 - accuracy: 0.9822\n",
      "Epoch 151/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0513 - accuracy: 0.9821\n",
      "Epoch 152/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0520 - accuracy: 0.9820\n",
      "Epoch 153/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0505 - accuracy: 0.9826\n",
      "Epoch 154/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0504 - accuracy: 0.9827\n",
      "Epoch 155/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0508 - accuracy: 0.9826\n",
      "Epoch 156/300\n",
      "153934/153934 [==============================] - 11s 72us/step - loss: 0.0505 - accuracy: 0.9826\n",
      "Epoch 157/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0501 - accuracy: 0.9828\n",
      "Epoch 158/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0498 - accuracy: 0.9828\n",
      "Epoch 159/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0496 - accuracy: 0.9826\n",
      "Epoch 160/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0496 - accuracy: 0.9831\n",
      "Epoch 161/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0489 - accuracy: 0.9831\n",
      "Epoch 162/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0496 - accuracy: 0.9829\n",
      "Epoch 163/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0486 - accuracy: 0.9830\n",
      "Epoch 164/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0491 - accuracy: 0.9831\n",
      "Epoch 165/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0486 - accuracy: 0.9831\n",
      "Epoch 166/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0490 - accuracy: 0.9831\n",
      "Epoch 167/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0483 - accuracy: 0.98330s - loss: 0.0483 - accuracy: 0.98\n",
      "Epoch 168/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0479 - accuracy: 0.9835\n",
      "Epoch 169/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0481 - accuracy: 0.9834\n",
      "Epoch 170/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0473 - accuracy: 0.9836\n",
      "Epoch 171/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0477 - accuracy: 0.9835\n",
      "Epoch 172/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0475 - accuracy: 0.9835\n",
      "Epoch 173/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0477 - accuracy: 0.9837\n",
      "Epoch 174/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0470 - accuracy: 0.9840\n",
      "Epoch 175/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0468 - accuracy: 0.9839\n",
      "Epoch 176/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0466 - accuracy: 0.9841\n",
      "Epoch 177/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0462 - accuracy: 0.9838\n",
      "Epoch 178/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0465 - accuracy: 0.9838\n",
      "Epoch 179/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0465 - accuracy: 0.9837\n",
      "Epoch 180/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0462 - accuracy: 0.9841\n",
      "Epoch 181/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0450 - accuracy: 0.9846\n",
      "Epoch 182/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0460 - accuracy: 0.9843\n",
      "Epoch 183/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0453 - accuracy: 0.9843\n",
      "Epoch 184/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0453 - accuracy: 0.9844\n",
      "Epoch 185/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0446 - accuracy: 0.9846\n",
      "Epoch 186/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0457 - accuracy: 0.9845\n",
      "Epoch 187/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0446 - accuracy: 0.9846\n",
      "Epoch 188/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0448 - accuracy: 0.9848\n",
      "Epoch 189/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0451 - accuracy: 0.9842\n",
      "Epoch 190/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0441 - accuracy: 0.9847\n",
      "Epoch 191/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0442 - accuracy: 0.9848\n",
      "Epoch 192/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0449 - accuracy: 0.9845\n",
      "Epoch 193/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0448 - accuracy: 0.9846\n",
      "Epoch 194/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0437 - accuracy: 0.9850\n",
      "Epoch 195/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0441 - accuracy: 0.9848\n",
      "Epoch 196/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0436 - accuracy: 0.9850\n",
      "Epoch 197/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0433 - accuracy: 0.9849\n",
      "Epoch 198/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0434 - accuracy: 0.9850\n",
      "Epoch 199/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0435 - accuracy: 0.9852\n",
      "Epoch 200/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0438 - accuracy: 0.9852\n",
      "Epoch 201/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0433 - accuracy: 0.9850\n",
      "Epoch 202/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0428 - accuracy: 0.9851\n",
      "Epoch 203/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0426 - accuracy: 0.9853\n",
      "Epoch 204/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0425 - accuracy: 0.9856\n",
      "Epoch 205/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0425 - accuracy: 0.9854\n",
      "Epoch 206/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0421 - accuracy: 0.9854\n",
      "Epoch 207/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0429 - accuracy: 0.9852\n",
      "Epoch 208/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0416 - accuracy: 0.9854\n",
      "Epoch 209/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0421 - accuracy: 0.9858\n",
      "Epoch 210/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0419 - accuracy: 0.9857\n",
      "Epoch 211/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0418 - accuracy: 0.9854\n",
      "Epoch 212/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0413 - accuracy: 0.9856\n",
      "Epoch 213/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0417 - accuracy: 0.9857\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0410 - accuracy: 0.9860\n",
      "Epoch 215/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0417 - accuracy: 0.9857\n",
      "Epoch 216/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0419 - accuracy: 0.9854\n",
      "Epoch 217/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0398 - accuracy: 0.9865\n",
      "Epoch 218/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0418 - accuracy: 0.9855\n",
      "Epoch 219/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0401 - accuracy: 0.9862\n",
      "Epoch 220/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0412 - accuracy: 0.9858\n",
      "Epoch 221/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0401 - accuracy: 0.9862\n",
      "Epoch 222/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0406 - accuracy: 0.9859\n",
      "Epoch 223/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0397 - accuracy: 0.9862\n",
      "Epoch 224/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0407 - accuracy: 0.9860\n",
      "Epoch 225/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0401 - accuracy: 0.9862\n",
      "Epoch 226/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0401 - accuracy: 0.9861\n",
      "Epoch 227/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0395 - accuracy: 0.9865\n",
      "Epoch 228/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0402 - accuracy: 0.9863\n",
      "Epoch 229/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0400 - accuracy: 0.9862\n",
      "Epoch 230/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0405 - accuracy: 0.9860\n",
      "Epoch 231/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0397 - accuracy: 0.9862\n",
      "Epoch 232/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0397 - accuracy: 0.9862\n",
      "Epoch 233/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0393 - accuracy: 0.9866\n",
      "Epoch 234/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0394 - accuracy: 0.9864\n",
      "Epoch 235/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0390 - accuracy: 0.9865\n",
      "Epoch 236/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0391 - accuracy: 0.9864\n",
      "Epoch 237/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0392 - accuracy: 0.9867\n",
      "Epoch 238/300\n",
      "153934/153934 [==============================] - 11s 68us/step - loss: 0.0392 - accuracy: 0.9868\n",
      "Epoch 239/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0390 - accuracy: 0.9867\n",
      "Epoch 240/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0390 - accuracy: 0.9864\n",
      "Epoch 241/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0385 - accuracy: 0.9868\n",
      "Epoch 242/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0391 - accuracy: 0.9866\n",
      "Epoch 243/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0384 - accuracy: 0.9868\n",
      "Epoch 244/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0374 - accuracy: 0.9872\n",
      "Epoch 245/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0379 - accuracy: 0.9868\n",
      "Epoch 246/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0386 - accuracy: 0.9866\n",
      "Epoch 247/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0380 - accuracy: 0.9868\n",
      "Epoch 248/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0376 - accuracy: 0.9869\n",
      "Epoch 249/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0378 - accuracy: 0.9866\n",
      "Epoch 250/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0383 - accuracy: 0.9866\n",
      "Epoch 251/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0380 - accuracy: 0.9869\n",
      "Epoch 252/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 253/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0377 - accuracy: 0.9872\n",
      "Epoch 254/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0371 - accuracy: 0.9872\n",
      "Epoch 255/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0374 - accuracy: 0.9872\n",
      "Epoch 256/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0366 - accuracy: 0.9876\n",
      "Epoch 257/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0381 - accuracy: 0.9870\n",
      "Epoch 258/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0372 - accuracy: 0.9872\n",
      "Epoch 259/300\n",
      "153934/153934 [==============================] - 10s 66us/step - loss: 0.0367 - accuracy: 0.9874\n",
      "Epoch 260/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0371 - accuracy: 0.9871\n",
      "Epoch 261/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0357 - accuracy: 0.9877\n",
      "Epoch 262/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0370 - accuracy: 0.9872\n",
      "Epoch 263/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0366 - accuracy: 0.9873\n",
      "Epoch 264/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0363 - accuracy: 0.9873\n",
      "Epoch 265/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0363 - accuracy: 0.9876\n",
      "Epoch 266/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0364 - accuracy: 0.9874\n",
      "Epoch 267/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0362 - accuracy: 0.9876\n",
      "Epoch 268/300\n",
      "153934/153934 [==============================] - 11s 71us/step - loss: 0.0364 - accuracy: 0.9877\n",
      "Epoch 269/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0363 - accuracy: 0.9877\n",
      "Epoch 270/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0351 - accuracy: 0.9880\n",
      "Epoch 271/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0359 - accuracy: 0.9876\n",
      "Epoch 272/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0354 - accuracy: 0.9876\n",
      "Epoch 273/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0358 - accuracy: 0.9877\n",
      "Epoch 274/300\n",
      "153934/153934 [==============================] - 11s 70us/step - loss: 0.0355 - accuracy: 0.9880\n",
      "Epoch 275/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 276/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0352 - accuracy: 0.9879\n",
      "Epoch 277/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0348 - accuracy: 0.9880\n",
      "Epoch 278/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0362 - accuracy: 0.9874\n",
      "Epoch 279/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0350 - accuracy: 0.9882\n",
      "Epoch 280/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0358 - accuracy: 0.9874\n",
      "Epoch 281/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0347 - accuracy: 0.9880\n",
      "Epoch 282/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0356 - accuracy: 0.9877\n",
      "Epoch 283/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0346 - accuracy: 0.9882\n",
      "Epoch 284/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0353 - accuracy: 0.9880\n",
      "Epoch 285/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0350 - accuracy: 0.9881\n",
      "Epoch 286/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0357 - accuracy: 0.9878\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0352 - accuracy: 0.9879\n",
      "Epoch 288/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0350 - accuracy: 0.9881\n",
      "Epoch 289/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 290/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0345 - accuracy: 0.9882\n",
      "Epoch 291/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0341 - accuracy: 0.9882\n",
      "Epoch 292/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0341 - accuracy: 0.9882\n",
      "Epoch 293/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0341 - accuracy: 0.9880\n",
      "Epoch 294/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0333 - accuracy: 0.9886\n",
      "Epoch 295/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0333 - accuracy: 0.9884\n",
      "Epoch 296/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0342 - accuracy: 0.9884\n",
      "Epoch 297/300\n",
      "153934/153934 [==============================] - 10s 67us/step - loss: 0.0340 - accuracy: 0.9886\n",
      "Epoch 298/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0339 - accuracy: 0.9885\n",
      "Epoch 299/300\n",
      "153934/153934 [==============================] - 10s 68us/step - loss: 0.0336 - accuracy: 0.9885\n",
      "Epoch 300/300\n",
      "153934/153934 [==============================] - 11s 69us/step - loss: 0.0341 - accuracy: 0.9886\n",
      "\n",
      "Training done in 52.67841383218765 minutes or 3160.704829931259 seconds now evaluating...\n",
      "\n",
      "153934/153934 [==============================] - 4s 28us/step\n",
      "\n",
      "38484/38484 [==============================] - 1s 28us/step\n",
      "[[0.9999939]]\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(vectorSize,))\n",
    "\n",
    "#x = Dense(8000, activation='sigmoid')(input_layer)\n",
    "\n",
    "#x = Dense(4000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(2000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(1000, activation='sigmoid')(x)\n",
    "\n",
    "#x = Dense(500, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(100, activation='sigmoid')(input_layer)\n",
    "\n",
    "x = Dense(50, activation='sigmoid')(x)\n",
    "\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mlp3 = keras.models.Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "mlp3.summary()\n",
    "\n",
    "\n",
    "#compile\n",
    "mlp3.compile(optimizer=opt, loss=lossType, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Starting training...\")\n",
    "print()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# fit the model\n",
    "mlp3.fit(trainSet, trainLabel, epochs=epochs_to_run, verbose=1)\n",
    "\n",
    "durationSecond = time.time()-start\n",
    "\n",
    "print()\n",
    "print(\"Training done in\",durationSecond/60,\"minutes or\",durationSecond,\"seconds now evaluating...\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "trainLoss, trainAccuracy = mlp3.evaluate(trainSet, trainLabel, verbose=1)\n",
    "#print('Training Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "testLoss, testAccuracy = mlp3.evaluate(testSet, testLabel, verbose=1)\n",
    "#print('Test Accuracy: %f' % (accuracy*100))\n",
    "\n",
    "\n",
    "word = \"dystrophin\"\n",
    "\n",
    "prediction = mlp3.predict(np.array([word2vec(word)]))\n",
    "\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "Dense3Results += [trainAccuracy,testAccuracy]\n",
    "\n",
    "#del model\n",
    "\n",
    "#backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "| Accuracy |       train        |        test        |\n",
      "+----------+--------------------+--------------------+\n",
      "|  Dense   | 0.9763275384902954 | 0.9468350410461426 |\n",
      "|  Dense   | 0.9849480986595154 | 0.9416381120681763 |\n",
      "|  Dense   | 0.9894630312919617 | 0.940208911895752  |\n",
      "+----------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "results = PrettyTable()\n",
    "\n",
    "\n",
    "\n",
    "results.field_names = [\"Accuracy\",\n",
    "                       \"train\",  \"test\"]#,\n",
    "                       #\"Train 300 epochs\", \"Test 300 epochs\",\n",
    "                       #\"Train 400 epochs\", \"Test 400 epochs\"]\n",
    "\n",
    "'''\n",
    "denseResults = [x*100 for x in denseResults]\n",
    "\n",
    "CNNResults = [x*100 for x in CNNResults]\n",
    "\n",
    "LSTMResults = [x*100 for x in LSTMResults]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results.add_row([\"Dense\"] + Dense1Results)\n",
    "\n",
    "results.add_row([\"Dense\"] + Dense2Results)\n",
    "\n",
    "results.add_row([\"Dense\"] + Dense3Results)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Practical results when applied to our list of proteins</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96355 proteins obtained\n",
      "\n",
      "93039 positive results\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for p in proteinVectors:\n",
    "    results +=[  mlp2.predict(np.array([p]))[0][0] ]\n",
    "\n",
    "print(len(results),\"proteins obtained\")\n",
    "print()\n",
    "\n",
    "positive = [r for r in results if r>0.5]\n",
    "print(len(positive),\"positive results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(mlp2, 'proteinRecognitionNetwork.pkl', compress=9)\n",
    "print(\"exported\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
